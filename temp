import pandas as pd
import torch
from torch_geometric.data import HeteroData
from torch_geometric.nn import RGCNConv
from sklearn.preprocessing import LabelEncoder

# Load your data
nodes_df = pd.read_csv("nodes.csv")  # columns: Name, Label, Msg, Time, Level, EventId, Service
edges_df = pd.read_csv("relationships.csv")  # columns: StartNode, EndNode, Edge

# Encode node features
node_encoder = LabelEncoder()
nodes_df['node_id'] = node_encoder.fit_transform(nodes_df['Name'])

# Build feature vectors
level_encoder = LabelEncoder()
service_encoder = LabelEncoder()
eventid_encoder = LabelEncoder()

nodes_df['LevelEnc'] = level_encoder.fit_transform(nodes_df['Level'].fillna("Unknown"))
nodes_df['ServiceEnc'] = service_encoder.fit_transform(nodes_df['Service'].fillna("Unknown"))
nodes_df['EventIdEnc'] = eventid_encoder.fit_transform(nodes_df['EventId'].fillna("Unknown"))

# Create feature tensor
features = torch.tensor(
    nodes_df[['LevelEnc', 'ServiceEnc', 'EventIdEnc']].values,
    dtype=torch.long
)

# Create HeteroData object
data = HeteroData()

# Separate log and param nodes
log_mask = nodes_df['Label'] == 'Log'
param_mask = nodes_df['Label'] == 'Param'

log_nodes = nodes_df[log_mask]
param_nodes = nodes_df[param_mask]

# Assign features
data['log'].x = features[log_mask.values]
data['param'].x = features[param_mask.values]  # if param has no features, use torch.zeros

# Map node names to indices
node_id_map = dict(zip(nodes_df['Name'], nodes_df['node_id']))

# Process edge_index per relation type
from collections import defaultdict
edge_index_dict = defaultdict(lambda: [[], []])

for _, row in edges_df.iterrows():
    source = node_id_map[row['StartNode']]
    target = node_id_map[row['EndNode']]
    rel_type = row['Edge']
    
    # Determine source and target types
    source_label = nodes_df.loc[nodes_df['node_id'] == source, 'Label'].values[0].lower()
    target_label = nodes_df.loc[nodes_df['node_id'] == target, 'Label'].values[0].lower()

    edge_index_dict[(source_label, rel_type, target_label)][0].append(source)
    edge_index_dict[(source_label, rel_type, target_label)][1].append(target)

# Convert to tensor and add to HeteroData
for (src_type, rel_type, dst_type), (src_list, dst_list) in edge_index_dict.items():
    edge_index = torch.tensor([src_list, dst_list], dtype=torch.long)
    data[(src_type, rel_type, dst_type)].edge_index = edge_index

# Define R-GCN model
from torch_geometric.nn import RGCNConv
from torch.nn import ModuleDict, Linear

class RGCN(torch.nn.Module):
    def __init__(self, in_channels, out_channels, metadata, num_relations):
        super().__init__()
        self.embeddings = torch.nn.ModuleDict()
        for node_type in metadata[0]:
            self.embeddings[node_type] = torch.nn.Linear(in_channels, 32)

        self.conv1 = RGCNConv(32, 64, num_relations)
        self.conv2 = RGCNConv(64, out_channels, num_relations)

    def forward(self, x_dict, edge_index, edge_type):
        x = {}
        for node_type, feats in x_dict.items():
            x[node_type] = self.embeddings[node_type](feats.float())

        x = torch.cat([x[k] for k in x], dim=0)
        x = self.conv1(x, edge_index, edge_type).relu()
        x = self.conv2(x, edge_index, edge_type)
        return x

# Convert HeteroData to homogeneous for RGCN
from torch_geometric.transforms import ToUndirected, ToHomogeneous
transform = ToHomogeneous(edge_type_attr='edge_type', node_type_attr='node_type')
data_homo = transform(data)

# Create and train model
model = RGCN(in_channels=3, out_channels=64, metadata=data.metadata(), num_relations=data_homo.num_edge_types)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Training loop
model.train()
for epoch in range(100):
    optimizer.zero_grad()
    out = model(data_homo.x_dict, data_homo.edge_index, data_homo.edge_type)
    loss = out.norm(p=2)  # dummy unsupervised loss
    loss.backward()
    optimizer.step()
    if epoch % 10 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

# The 'out' tensor now contains embeddings for all nodes
embeddings = out.detach()
