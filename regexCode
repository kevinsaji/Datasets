from drain3 import TemplateMiner
from drain3.template_miner_config import TemplateMinerConfig
from drain3.persistence_handler import PersistenceHandler
import pandas as pd
import re
import json

# Initialize config manually
config = TemplateMinerConfig()
config.set("drain_depth", 5)
config.set("max_children", 100)
config.set("fixed_depth", 4)
config.set("extra_delimiters", "=:,")
config.set("sim_th", 0.5)

# Optionally use persistence
persistence_handler = PersistenceHandler("drain3_state.json")
template_miner = TemplateMiner(config=config, persistence_handler=persistence_handler)

# Input and output files
INPUT_FILE = "logs.csv"
PARSED_OUTPUT = "parsed_logs.csv"
TEMPLATES_OUTPUT = "templates.csv"

# Read logs
df = pd.read_csv(INPUT_FILE)

parsed_rows = []

for line_id, row in df.iterrows():
    content = str(row['content'])
    result = template_miner.add_log_message(content)

    if not result:
        continue

    parsed_rows.append({
        "line_id": line_id,
        "time": row['time'],
        "level": row['level'],
        "content": content,
        "event_id": result["cluster_id"],
        "event_template": result["template_mined"],
        "parameter_list": json.dumps(result["params"])
    })

# Save parsed logs
parsed_df = pd.DataFrame(parsed_rows)
parsed_df.to_csv(PARSED_OUTPUT, index=False)

# Save templates
template_records = [
    {
        "event_id": cluster.cluster_id,
        "event_template": cluster.get_template(),
        "occurrences": cluster.size
    }
    for cluster in template_miner.drain.clusters.get_clusters()
]

template_df = pd.DataFrame(template_records)
template_df.to_csv(TEMPLATES_OUTPUT, index=False)

print(f"✅ Parsed logs saved to {PARSED_OUTPUT}")
print(f"✅ Templates saved to {TEMPLATES_OUTPUT}")
